{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "\n",
    "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A more precise measurement, such as a urine al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the symptoms of Fraser like syndrome ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most cases of shingles occur in adults. Only a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is Bilateral perisylvian polymicrogyria inheri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\",GARD,Coccygodynia What are the treatments fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77802</th>\n",
       "      <td>In the fatal cases (4/5 patients), a transient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77803</th>\n",
       "      <td>This chemical robs your blood of oxygen and tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77804</th>\n",
       "      <td>Physical Activity Being physically active and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77805</th>\n",
       "      <td>\",GARD,Faciocardiorenal syndrome What is (are)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77806</th>\n",
       "      <td>\",GARD,3-Hydroxyisobutyric aciduria Is 3-Hydro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77807 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  corpus\n",
       "0      A more precise measurement, such as a urine al...\n",
       "1      What are the symptoms of Fraser like syndrome ...\n",
       "2      Most cases of shingles occur in adults. Only a...\n",
       "3      Is Bilateral perisylvian polymicrogyria inheri...\n",
       "4      \",GARD,Coccygodynia What are the treatments fo...\n",
       "...                                                  ...\n",
       "77802  In the fatal cases (4/5 patients), a transient...\n",
       "77803  This chemical robs your blood of oxygen and tr...\n",
       "77804  Physical Activity Being physically active and ...\n",
       "77805  \",GARD,Faciocardiorenal syndrome What is (are)...\n",
       "77806  \",GARD,3-Hydroxyisobutyric aciduria Is 3-Hydro...\n",
       "\n",
       "[77807 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/dataset.csv')\n",
    "df['corpus'] = df['corpus'].astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chromosome territories are also dynamic structures, with genes able to relocate from the periphery towards the interior once they have been switched on. in other cases, genes may move in the opposite direction, or simply maintain their position. chromosome territories can reposition in diseases, which might provide novel insights into disease mechanisms and why genes are incorrectly expressed in diseases.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = df['corpus'].values\n",
    "samples[-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer_params = dict(lower_case=True)\n",
    "tokenizer = text.BertTokenizer('vocab.txt', **bert_tokenizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128)\n",
      "(32, 128)\n",
      "Input: [222  86 104 119 297 113 320  15  42 304]\n",
      "Output: [ 86 104 119 297 113 320  15  42 304 161]\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 32\n",
    "MAX_TOKENS = 129\n",
    "\n",
    "def prepare_data(token):\n",
    "      token = token[:MAX_TOKENS]\n",
    "      input = token[:-1]\n",
    "      label = token[1:]\n",
    "      \n",
    "      return input, label\n",
    "\n",
    "train_dataset = tokenizer.tokenize(samples[15561:]).merge_dims(-2,-1).to_tensor()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset)\n",
    "train_dataset = train_dataset.map(prepare_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tokenizer.tokenize(samples[:15561]).merge_dims(-2,-1).to_tensor()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(val_dataset)\n",
    "val_dataset = val_dataset.map(prepare_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "for x_train, y_train in train_dataset.take(1):\n",
    "      break\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Input:', x_train[0][:10].numpy())\n",
    "print('Output:', y_train[0][:10].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "    angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis=-1) \n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x,\n",
    "            use_causal_mask = True)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),\n",
    "            tf.keras.layers.Dense(d_model),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.causal_self_attention = CausalSelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=d_model,\n",
    "            dropout=dropout_rate)\n",
    "\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.causal_self_attention(x=x)\n",
    "        x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                        dff=dff, dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "\n",
    "        self.last_attn_scores = None\n",
    "\n",
    "    def call(self, x):\n",
    "        # `x` is token-IDs shape (batch, target_seq_len)\n",
    "        x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x)\n",
    "\n",
    "        # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, *, num_layers, d_model, num_heads, dff, target_vocab_size, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                            num_heads=num_heads, dff=dff,\n",
    "                            vocab_size=target_vocab_size,\n",
    "                            dropout_rate=dropout_rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "        # first argument.\n",
    "\n",
    "        x = self.decoder(x)  # (batch_size, target_len, d_model)\n",
    "\n",
    "        # Final linear layer output.\n",
    "        logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "        # Return the final output and the attention weights.\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "vocab_size = 7951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128)\n",
      "(32, 128, 7951)\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    target_vocab_size=vocab_size,\n",
    "    dropout_rate=dropout_rate)\n",
    "\n",
    "output = transformer(x_train)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder (Decoder)           multiple                  3656576   \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  1025679   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,682,255\n",
      "Trainable params: 4,682,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "    mask = label != 0\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = loss_object(label, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "    pred = tf.argmax(pred, axis=2)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    match = label == pred\n",
    "\n",
    "    mask = label != 0\n",
    "\n",
    "    match = match & mask\n",
    "\n",
    "    match = tf.cast(match, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_masked_accuracy', patience=3)\n",
    "transformer.compile(loss=masked_loss, optimizer=optimizer, metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1818b7ec700>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads the weights\n",
    "transformer.load_weights('./model/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1946/1946 [==============================] - 534s 274ms/step - loss: 1.2535 - masked_accuracy: 0.5845 - val_loss: 1.2379 - val_masked_accuracy: 0.6011\n",
      "Epoch 2/5\n",
      "1946/1946 [==============================] - 544s 279ms/step - loss: 1.2486 - masked_accuracy: 0.5855 - val_loss: 1.2355 - val_masked_accuracy: 0.6025\n",
      "Epoch 3/5\n",
      "1946/1946 [==============================] - 545s 280ms/step - loss: 1.2439 - masked_accuracy: 0.5867 - val_loss: 1.2341 - val_masked_accuracy: 0.6028\n",
      "Epoch 4/5\n",
      "1946/1946 [==============================] - 548s 281ms/step - loss: 1.2395 - masked_accuracy: 0.5879 - val_loss: 1.2324 - val_masked_accuracy: 0.6030\n",
      "Epoch 5/5\n",
      "1946/1946 [==============================] - 546s 280ms/step - loss: 1.2350 - masked_accuracy: 0.5888 - val_loss: 1.2306 - val_masked_accuracy: 0.6038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab57361c70>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(train_dataset, epochs=5, validation_data=val_dataset, callbacks=[es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights('./model/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x181aad6aee0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads the new weights\n",
    "transformer.load_weights('./model/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(sentence, maxlen=MAX_TOKENS):\n",
    "    output_array = tokenizer.tokenize(sentence).merge_dims(-2, -1).to_tensor()\n",
    "    \n",
    "    for i in range(maxlen):\n",
    "        prediction = transformer(output_array, training=False)\n",
    "        prediction = prediction[:, -1:, :]\n",
    "        prediction = tf.argmax(prediction, axis=-1)\n",
    "        output_array = tf.concat([output_array, prediction], axis=1)\n",
    "        \n",
    "        if prediction[0][0].numpy() == 3:\n",
    "            break\n",
    "        \n",
    "    output = tokenizer.detokenize(output_array).to_tensor()\n",
    "    output = ' '.join([word.decode('utf-8') for word in output.numpy()[0]])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what is type 2 diabetes ? type 2 diabetes is a disease in which the body is unable to use insulin effectively . the body is unable to use insulin effectively , which means that it is unable to use insulin effectively . type 2 diabetes develops when the body doesnt make enough insulin or is not able to use insulin effectively , or both . type 2 diabetes is a disease in which the body doesnt use insulin effectively . type 2 diabetes develops when the body doesnt make enough insulin or is not able to use insulin effectively , or both . type 2 diabetes is a disease in which the body doesnt make enough insulin or doesnt use insulin effectively . type 2 diabetes is a disease in which the body '\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text('what is type 2 diabetes?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is insulin ? insulin is a hormone that helps the body make insulin . insulin is a hormone that helps the body use for energy . insulin helps the body make insulin and helps the body make energy . insulin is a hormone that helps the body use for energy . insulin helps the body make insulin . insulin helps the body make insulin and helps the body make insulin . insulin is a hormone that helps the body use glucose for energy . insulin helps cells make glucose for energy . insulin helps the body make glucose for energy . insulin is a hormone that helps the body use glucose for energy . insulin is a hormone that helps the body use glucose for energy . insulin is a hormone that'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text('what is insulin?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('transformer_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5ef8c4b80788ce44ced42bcb28e414f75089d47a94a3a967df09102d2c56b2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
