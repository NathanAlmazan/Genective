{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "\n",
    "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in the letter, the doctor should also include ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>children and adolescents with type 2 diabetes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prepare a list of questions before your visit....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if your blood has too much or too little gluco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>remember, the closer you get to your target ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>diabetes is when your blood glucose, also call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>some people use an insulin pen, a pen like dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>if you plan to have a baby, work with your hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>ask your health care team about how to adjust ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>you can learn how to take care of your diabete...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                corpus\n",
       "0    in the letter, the doctor should also include ...\n",
       "1    children and adolescents with type 2 diabetes ...\n",
       "2    prepare a list of questions before your visit....\n",
       "3    if your blood has too much or too little gluco...\n",
       "4    remember, the closer you get to your target ra...\n",
       "..                                                 ...\n",
       "134  diabetes is when your blood glucose, also call...\n",
       "135  some people use an insulin pen, a pen like dev...\n",
       "136  if you plan to have a baby, work with your hea...\n",
       "137  ask your health care team about how to adjust ...\n",
       "138  you can learn how to take care of your diabete...\n",
       "\n",
       "[139 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/corpus_1.csv')\n",
    "df['corpus'] = df['corpus'].astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'these charts list important things you should discuss with your doctor at each visit. things to discuss with your health care team at each visit date: whom you visited: your information things to remember check off what you covered, or write the result of your visit. your blood glucose levels share your blood glucose records.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = df['corpus'].values\n",
    "samples[-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer_params = dict(lower_case=True)\n",
    "tokenizer = text.BertTokenizer('vocab.txt', **bert_tokenizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128)\n",
      "(32, 128)\n",
      "Input: [ 116  100  206   42 2544   90  293  175  180   29]\n",
      "Output: [ 100  206   42 2544   90  293  175  180   29  710]\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 32\n",
    "MAX_TOKENS = 129\n",
    "\n",
    "def prepare_data(token):\n",
    "      token = token[:MAX_TOKENS]\n",
    "      input = token[:-1]\n",
    "      label = token[1:]\n",
    "      \n",
    "      return input, label\n",
    "\n",
    "train_dataset = tokenizer.tokenize(samples[:125]).merge_dims(-2,-1).to_tensor()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset)\n",
    "train_dataset = train_dataset.map(prepare_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tokenizer.tokenize(samples[125:]).merge_dims(-2,-1).to_tensor()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(val_dataset)\n",
    "val_dataset = val_dataset.map(prepare_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "for x_train, y_train in train_dataset.take(1):\n",
    "      break\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Input:', x_train[0][:10].numpy())\n",
    "print('Output:', y_train[0][:10].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "    angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis=-1) \n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x,\n",
    "            use_causal_mask = True)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),\n",
    "            tf.keras.layers.Dense(d_model),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.causal_self_attention = CausalSelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=d_model,\n",
    "            dropout=dropout_rate)\n",
    "\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.causal_self_attention(x=x)\n",
    "        x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                        dff=dff, dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "\n",
    "        self.last_attn_scores = None\n",
    "\n",
    "    def call(self, x):\n",
    "        # `x` is token-IDs shape (batch, target_seq_len)\n",
    "        x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x)\n",
    "\n",
    "        # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, *, num_layers, d_model, num_heads, dff, target_vocab_size, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                            num_heads=num_heads, dff=dff,\n",
    "                            vocab_size=target_vocab_size,\n",
    "                            dropout_rate=dropout_rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "        # first argument.\n",
    "\n",
    "        x = self.decoder(x)  # (batch_size, target_len, d_model)\n",
    "\n",
    "        # Final linear layer output.\n",
    "        logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "        # Return the final output and the attention weights.\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "vocab_size = 7951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128)\n",
      "(32, 128, 7951)\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    target_vocab_size=vocab_size,\n",
    "    dropout_rate=dropout_rate)\n",
    "\n",
    "output = transformer(x_train)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder (Decoder)           multiple                  3656576   \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  1025679   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,682,255\n",
      "Trainable params: 4,682,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "    mask = label != 0\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = loss_object(label, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "    pred = tf.argmax(pred, axis=2)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    match = label == pred\n",
    "\n",
    "    mask = label != 0\n",
    "\n",
    "    match = match & mask\n",
    "\n",
    "    match = tf.cast(match, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_masked_accuracy', patience=3)\n",
    "transformer.compile(loss=masked_loss, optimizer=optimizer, metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1ef9463ceb0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads the weights\n",
    "transformer.load_weights('./model/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.4492 - masked_accuracy: 0.7689 - val_loss: 1.1997 - val_masked_accuracy: 0.5228\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.4063 - masked_accuracy: 0.7903 - val_loss: 1.2106 - val_masked_accuracy: 0.5194\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.3770 - masked_accuracy: 0.8060 - val_loss: 1.2264 - val_masked_accuracy: 0.5171\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.3450 - masked_accuracy: 0.8199 - val_loss: 1.2449 - val_masked_accuracy: 0.5137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ee96394820>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(train_dataset, epochs=10, validation_data=val_dataset, callbacks=[es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights('./model/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1f06a47ad30>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads the new weights\n",
    "transformer.load_weights('./model/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(sentence, maxlen=MAX_TOKENS):\n",
    "    output_array = tokenizer.tokenize(sentence).merge_dims(-2, -1).to_tensor()\n",
    "    \n",
    "    for i in range(maxlen):\n",
    "        prediction = transformer(output_array, training=False)\n",
    "        prediction = prediction[:, -1:, :]\n",
    "        prediction = tf.argmax(prediction, axis=-1)\n",
    "        output_array = tf.concat([output_array, prediction], axis=1)\n",
    "        \n",
    "        if prediction[0][0].numpy() == 3:\n",
    "            break\n",
    "        \n",
    "    output = tokenizer.detokenize(output_array).to_tensor()\n",
    "    output = ' '.join([word.decode('utf-8') for word in output.numpy()[0]])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what is type 2 diabetes ? type 2 diabetes is a disease in which the body does not produce enough insulin . the body ' s immune system attacks the bodys own cells and organs . the pancreas is the organ that makes more insulin . the pancreas is the organ that makes up the body ' s cells . the pancreas is the organ that makes up the body ' s immune system . the pancreas is the organ that makes up the body ' s immune system . the pancreas is the organ that makes up the body ' s immune system . the pancreas is the organ that makes antibodies to identify foreign substances . the pancreas is the organ that makes antibodies to attack and attack healthy cells . in the\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text('what is type 2 diabetes?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what is insulin ? insulin resistance is a condition in which the body ' s cells are unable to use insulin effectively . insulin is a hormone that helps the body use insulin effectively , which means that it is not able to use insulin effectively , or both . insulin is a hormone that helps the body use insulin to help the body use insulin effectively . insulin is a hormone that helps the body use insulin to help the body use insulin effectively . insulin is a hormone that helps the body use insulin to help the body use insulin effectively . insulin is a hormone that helps the body use insulin to make insulin . insulin helps the body use glucose for energy . insulin is a hormone that helps\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text('what is insulin?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('transformer_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5ef8c4b80788ce44ced42bcb28e414f75089d47a94a3a967df09102d2c56b2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
